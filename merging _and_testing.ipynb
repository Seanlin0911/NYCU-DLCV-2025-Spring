{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11162372,"sourceType":"datasetVersion","datasetId":6965306},{"sourceId":301459,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":257464,"modelId":278763},{"sourceId":301682,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":257649,"modelId":278934}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport pandas as pd\nimport os\nprint(\"import finish\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:37:36.527026Z","iopub.execute_input":"2025-03-25T16:37:36.527474Z","iopub.status.idle":"2025-03-25T16:37:44.694820Z","shell.execute_reply.started":"2025-03-25T16:37:36.527434Z","shell.execute_reply":"2025-03-25T16:37:44.693488Z"}},"outputs":[{"name":"stdout","text":"import finish\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"transform = {\n    'train':transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n    'val':transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n}\nprint(\"transform finish\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:37:47.971373Z","iopub.execute_input":"2025-03-25T16:37:47.972098Z","iopub.status.idle":"2025-03-25T16:37:47.980286Z","shell.execute_reply.started":"2025-03-25T16:37:47.972053Z","shell.execute_reply":"2025-03-25T16:37:47.978987Z"}},"outputs":[{"name":"stdout","text":"transform finish\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"batch_size = 32\nnum_workers = 2  \npin_memory = True if torch.cuda.is_available() else False \ntest_dir = \"/kaggle/input/testdata/test\"\nclass TestDataset(Dataset):\n    def __init__(self, test_dir, transform=None):\n        self.test_dir = test_dir\n        self.transform = transform\n        self.image_names = os.listdir(test_dir) \n    \n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, idx):\n        image_name = self.image_names[idx]\n        image_path = os.path.join(self.test_dir, image_name)\n        image = Image.open(image_path).convert(\"RGB\") \n        \n        if self.transform:\n            image = self.transform(image)\n        \n        image = image.to(device)\n\n        return image_name, image \n\ntest_dataset = TestDataset(test_dir=test_dir, transform=transform)\ntest_loader = DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory\n)\n\nprint(\"✅ Data is ready! test datasets are loaded.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:37:50.537113Z","iopub.execute_input":"2025-03-25T16:37:50.537448Z","iopub.status.idle":"2025-03-25T16:37:50.682135Z","shell.execute_reply.started":"2025-03-25T16:37:50.537420Z","shell.execute_reply":"2025-03-25T16:37:50.680721Z"}},"outputs":[{"name":"stdout","text":"✅ Data is ready! test datasets are loaded.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nmodel1 = models.resnext50_32x4d(weights=None)\nmodel1.fc = torch.nn.Linear(model1.fc.in_features, 100)\n\nmodel1.load_state_dict(torch.load(\"/kaggle/input/model1/pytorch/default/1/finetuned_resnext50.pth\", map_location=\"cpu\"))\nmodel1.to(device)  \nmodel1.eval()  \n\nmodel2 = models.resnext101_32x8d(weights=None)\nmodel2.fc = torch.nn.Linear(model2.fc.in_features, 100)\n\nmodel2.load_state_dict(torch.load(\"/kaggle/input/model2/pytorch/default/1/finetuned_resnext50.pth\", map_location=\"cpu\"))\nmodel2.to(device\nmodel2.eval()  \ntotal_params = sum(p.numel() for p in model2.parameters())\ntrainable_params = sum(\n    p.numel() for p in model2.parameters() if p.requires_grad\n)\n\nprint(f\"Total parameters: {total_params}\")\nprint(f\"Trainable parameters: {trainable_params}\")\nprint(\"✅ Models loaded and moved to GPU!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:45:40.432543Z","iopub.execute_input":"2025-03-25T16:45:40.432891Z","iopub.status.idle":"2025-03-25T16:45:42.429797Z","shell.execute_reply.started":"2025-03-25T16:45:40.432863Z","shell.execute_reply":"2025-03-25T16:45:42.428719Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-15-95b02ad9ecb2>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model1.load_state_dict(torch.load(\"/kaggle/input/model1/pytorch/default/1/finetuned_resnext50.pth\", map_location=\"cpu\"))\n<ipython-input-15-95b02ad9ecb2>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model2.load_state_dict(torch.load(\"/kaggle/input/model2/pytorch/default/1/finetuned_resnext50.pth\", map_location=\"cpu\"))\n","output_type":"stream"},{"name":"stdout","text":"Total parameters: 86947236\nTrainable parameters: 86947236\n✅ Models loaded and moved to GPU!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def predict_with_two_models(image_path, model1, model2, transform, topk=5):\n    image = Image.open(image_path).convert('RGB')\n    image = transform(image).unsqueeze(0).to(device)\n    \n    with torch.no_grad():\n        outputs1 = model1(image)\n        outputs2 = model2(image)\n\n        probs1 = torch.nn.functional.softmax(outputs1, dim=1)\n        probs2 = torch.nn.functional.softmax(outputs2, dim=1)\n\n        avg_probs = (probs1 + probs2) / 2  \n        \n        top_probs, top_labels = torch.topk(avg_probs, topk)\n    \n    return top_labels.squeeze().cpu().tolist()\n    \nimage_folder = \"/kaggle/input/testdata/test\"\noutput_csv = \"./prediction.csv\"\n\npredictions = []\nfor image_name in os.listdir(image_folder):\n    image_path = os.path.join(image_folder, image_name)\n    top5_labels = predict_with_two_models(image_path, model1, model2, transform['val'], topk=5)\n    \n    pred_label = top5_labels[0]\n    predictions.append([image_name.replace('.jpg', ''), pred_label])\n\noutput_csv = \"./merged_prediction.csv\"\npd.DataFrame(predictions, columns=[\"image_name\", \"pred_label\"]).to_csv(output_csv, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:48:43.167246Z","iopub.execute_input":"2025-03-25T16:48:43.167546Z","iopub.status.idle":"2025-03-25T16:48:43.270813Z","shell.execute_reply.started":"2025-03-25T16:48:43.167508Z","shell.execute_reply":"2025-03-25T16:48:43.269522Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e1b0fc31906e>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtop5_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_two_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"],"ename":"NameError","evalue":"name 'os' is not defined","output_type":"error"}],"execution_count":1}]}