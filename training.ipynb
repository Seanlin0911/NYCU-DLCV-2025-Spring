{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11148174,"sourceType":"datasetVersion","datasetId":6954923}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torchvision import models\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport pandas as pd\nimport os\nprint(\"import finish\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:40:31.890525Z","iopub.execute_input":"2025-03-25T13:40:31.890745Z","iopub.status.idle":"2025-03-25T13:40:38.126944Z","shell.execute_reply.started":"2025-03-25T13:40:31.890711Z","shell.execute_reply":"2025-03-25T13:40:38.126220Z"}},"outputs":[{"name":"stdout","text":"import finish\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = models.resnext101_32x8d(weights=models.ResNeXt101_32X8D_Weights.DEFAULT).to(device)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:41:51.789140Z","iopub.execute_input":"2025-03-25T13:41:51.789462Z","iopub.status.idle":"2025-03-25T13:41:58.387192Z","shell.execute_reply.started":"2025-03-25T13:41:51.789437Z","shell.execute_reply":"2025-03-25T13:41:58.386392Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-110c445d.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_32x8d-110c445d.pth\n100%|██████████| 340M/340M [00:04<00:00, 84.3MB/s] \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"num_ftrs = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_ftrs, 100).to(device)\nprint(\"fc setting finish\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T08:35:25.275283Z","iopub.execute_input":"2025-03-25T08:35:25.275624Z","iopub.status.idle":"2025-03-25T08:35:25.283023Z","shell.execute_reply.started":"2025-03-25T08:35:25.275594Z","shell.execute_reply":"2025-03-25T08:35:25.282188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = {\n    'train':transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n    'val':transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n}\nprint(\"transform finish\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T08:35:27.986395Z","iopub.execute_input":"2025-03-25T08:35:27.986684Z","iopub.status.idle":"2025-03-25T08:35:27.992668Z","shell.execute_reply.started":"2025-03-25T08:35:27.986661Z","shell.execute_reply":"2025-03-25T08:35:27.991686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import datasets\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nfrom PIL import Image\n\n\ntrain_dir = \"/kaggle/input/training-data/train/train\"\nval_dir = \"/kaggle/input/training-data/val/val\"\ntest_dir = \"/kaggle/input/training-data/test/test\"  \n\nbatch_size = 32\nnum_workers = 2  \npin_memory = True if torch.cuda.is_available() else False\n\ntrain_dataset = datasets.ImageFolder(root=train_dir, transform=transform['train'])\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory\n)\n\nval_dataset = datasets.ImageFolder(root=val_dir, transform=transform['val'])\nval_loader = DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory\n)\nidx_to_class = {v: k for k, v in train_dataset.class_to_idx.items()}\n\nclass TestDataset(Dataset):\n    def __init__(self, test_dir, transform=None):\n        self.test_dir = test_dir\n        self.transform = transform\n        self.image_names = os.listdir(test_dir) \n    \n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, idx):\n        image_name = self.image_names[idx]\n        image_path = os.path.join(self.test_dir, image_name)\n        image = Image.open(image_path).convert(\"RGB\") \n        \n        if self.transform:\n            image = self.transform(image)\n        \n        image = image.to(device)\n\n        return image_name, image \n\ntest_dataset = TestDataset(test_dir=test_dir, transform=transform)\ntest_loader = DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory\n)\n\nprint(\"✅ Data is ready! Training, validation, and test datasets are loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:13:05.458299Z","iopub.execute_input":"2025-03-25T09:13:05.458647Z","iopub.status.idle":"2025-03-25T09:13:05.780810Z","shell.execute_reply.started":"2025-03-25T09:13:05.458622Z","shell.execute_reply":"2025-03-25T09:13:05.779982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 32\nepochs = 10\nlearning_rate = 0.0001","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:13:10.693692Z","iopub.execute_input":"2025-03-25T09:13:10.694034Z","iopub.status.idle":"2025-03-25T09:13:10.697643Z","shell.execute_reply.started":"2025-03-25T09:13:10.694006Z","shell.execute_reply":"2025-03-25T09:13:10.696749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:13:12.688998Z","iopub.execute_input":"2025-03-25T09:13:12.689296Z","iopub.status.idle":"2025-03-25T09:13:12.695516Z","shell.execute_reply.started":"2025-03-25T09:13:12.689272Z","shell.execute_reply":"2025-03-25T09:13:12.694860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train()\nbest_val_acc = 0\nfor epoch in range(epochs):\n    \n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        labels = torch.tensor([int(idx_to_class[label.item()])for label in labels]).to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        _, predicted = outputs.max(1)\n        correct += predicted.eq(labels).sum().item()\n        total += labels.size(0)\n\n    train_acc = 100.0 * correct / total\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            labels = torch.tensor([int(idx_to_class[label.item()])for label in labels]).to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            \n            _, predicted = outputs.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n\n    val_acc = 100.0 * correct / total\n    print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Validation Acc: {val_acc:.2f}%\\n\")\n    \n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), \"best_model.pth\") \n        print(f\"Best model saved with Validation Acc: {best_val_acc:.2f}%\\n\")\n    \n    model.train() \n\nprint(\"Training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:13:15.559381Z","iopub.execute_input":"2025-03-25T09:13:15.559669Z","iopub.status.idle":"2025-03-25T09:18:32.234810Z","shell.execute_reply.started":"2025-03-25T09:13:15.559647Z","shell.execute_reply":"2025-03-25T09:18:32.233994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"finetuned_resnext101.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T08:41:23.103140Z","iopub.execute_input":"2025-03-25T08:41:23.103435Z","iopub.status.idle":"2025-03-25T08:41:23.243850Z","shell.execute_reply.started":"2025-03-25T08:41:23.103411Z","shell.execute_reply":"2025-03-25T08:41:23.242982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:18:54.694554Z","iopub.execute_input":"2025-03-25T09:18:54.694850Z","iopub.status.idle":"2025-03-25T09:18:54.702620Z","shell.execute_reply.started":"2025-03-25T09:18:54.694828Z","shell.execute_reply":"2025-03-25T09:18:54.701759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nimport torch\n\ndef predict_image(image_path, model, transform, topk=5):\n    image = Image.open(image_path).convert('RGB')\n    image = transform(image).unsqueeze(0).to(device)\n    \n    with torch.no_grad():\n        outputs = model(image)\n        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n        top_probs, top_labels = torch.topk(probabilities, topk)\n    \n    return top_labels.squeeze().cpu().tolist()\n\nimage_folder = \"/kaggle/input/training-data/test/test\"\noutput_csv = \"./prediction.csv\"\n\nmodel = model.to(device)\n\npredictions = []\n\nfor image_name in os.listdir(image_folder):\n    image_path = os.path.join(image_folder, image_name)\n    \n    top5_labels = predict_image(image_path, model, transform['val'], topk=5) \n    \n    pred_label = top5_labels[0]\n    \n    image_name_without_extension = os.path.splitext(image_name)[0]\n    \n    predictions.append([image_name_without_extension, pred_label])\n\npred_df = pd.DataFrame(predictions, columns=[\"image_name\", \"pred_label\"])\npred_df.to_csv(output_csv, index=False)\n\nprint(f\"Predictions saved to {output_csv}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:19:00.265410Z","iopub.execute_input":"2025-03-25T09:19:00.265692Z","iopub.status.idle":"2025-03-25T09:19:47.371310Z","shell.execute_reply.started":"2025-03-25T09:19:00.265671Z","shell.execute_reply":"2025-03-25T09:19:47.370495Z"}},"outputs":[],"execution_count":null}]}